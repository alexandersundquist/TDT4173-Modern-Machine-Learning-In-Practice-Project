{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data sets\n",
    "X_train = pd.read_csv('ais_train.csv', sep='|')\n",
    "X_test = pd.read_csv('ais_test.csv')\n",
    "\n",
    "# Import ports data\n",
    "ports = pd.read_csv(\"ports.csv\", sep=\"|\")\n",
    "\n",
    "# Import vessels data\n",
    "vessels = pd.read_csv(\"vessels.csv\", sep=\"|\")\n",
    "\n",
    "#Import schedules data\n",
    "schedules = pd.read_csv(\"schedules_to_may_2024.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_train,df_test):\n",
    "    train = df_train.copy()\n",
    "    test = df_test.copy()\n",
    "\n",
    "    # Format time\n",
    "    train['time'] = pd.to_datetime(train['time'])\n",
    "    test['time'] = pd.to_datetime(test['time'])\n",
    "\n",
    "    # Factorize the 'vesselID' column in X_train and get the integer IDs and the mapping\n",
    "    vesselID, vesselID_mapping = pd.factorize(train['vesselId'])\n",
    "\n",
    "    # Replace 'vessel_ID' column in X_train with integer IDs\n",
    "    train['vesselId'] = vesselID\n",
    "\n",
    "    # Create a dictionary from the mapping to apply the same to X_test\n",
    "    vessel_to_ID = {vessel: idx for idx, vessel in enumerate(vesselID_mapping)}\n",
    "\n",
    "    # Replace 'vesselID' in X_test using the same mapping from X_train\n",
    "    test['vesselId'] = test['vesselId'].map(vessel_to_ID)\n",
    "    \n",
    "    # Replace 'portId' column with integer IDs\n",
    "    train['portId'] = pd.factorize(train['portId'])[0]\n",
    "\n",
    "    # Remove sog outliers\n",
    "    train = train[train['sog'] <= 40]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df_train,df_test):  \n",
    "    train = df_train.copy()\n",
    "    test = df_test.copy()\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Add the columns vesselId, time, latitude and longitude to the features from train\n",
    "    features['vesselId'] = train['vesselId']\n",
    "    features['time'] = train['time']\n",
    "    features['latitude'] = train['latitude']\n",
    "    features['longitude'] = train['longitude']\n",
    "\n",
    "    # Sort by vesselID then time\n",
    "    features = features.sort_values(['vesselId','time'])\n",
    "\n",
    "    # Add the columns last_longitude and last_latitude for every row in train\n",
    "    features['last_latitude'] = train.groupby('vesselId')['latitude'].shift()    \n",
    "    features['last_longitude'] = train.groupby('vesselId')['longitude'].shift()\n",
    "\n",
    "    # Remove the first row for every vesselId\n",
    "    features = features.dropna()\n",
    "\n",
    "    # New feature for if the vessel is moored or not\n",
    "    features['not_under_way'] = train['navstat'].apply(lambda x: 1 if x == 5 or x == 1 else 0)\n",
    "    features['under_way'] = train['navstat'].apply(lambda x: 1 if x == 0 or x == 8 else 0)\n",
    "\n",
    "    # Add the column cog, sog, and rot to the features from train\n",
    "    features['cog'] = train['cog']\n",
    "    features['sog'] = train['sog']\n",
    "    features['rot'] = train['rot']\n",
    "    features['heading'] = train['heading']\n",
    "\n",
    "    # Extract calendar features for 'etaRaw'\n",
    "    features[['etaMonth', 'etaDay', 'etaHour', 'etaMinute']] = train['etaRaw'].str.extract(r'(\\d{2})-(\\d{2}) (\\d{2}):(\\d{2})')\n",
    "    # Convert objects to integers\n",
    "    features[['etaMonth', 'etaDay', 'etaHour', 'etaMinute']] = features[['etaMonth', 'etaDay', 'etaHour', 'etaMinute']].astype(int)\n",
    "\n",
    "    # Split the time column into month, day, hour, minute and second columns\n",
    "    features['month'] = train['time'].dt.month\n",
    "    features['day'] = train['time'].dt.day\n",
    "    features['hour'] = train['time'].dt.hour\n",
    "    features['minute'] = train['time'].dt.minute\n",
    "    features['second'] = train['time'].dt.second\n",
    "\n",
    "    features.drop(columns=['time'], inplace=True)\n",
    "\n",
    "    return features, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,test = preprocess(X_train,X_test)\n",
    "features,test = feature_engineering(features,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and targets\n",
    "y = features[['latitude', 'longitude']]\n",
    "x = features.drop(columns=['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest regressor\n",
    "#rf_model = RandomForestRegressor()\n",
    "\n",
    "# Train the model\n",
    "#rf_model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [      0       1       2 ... 1469692 1469693 1469694], got [-167.54093 -167.48913 -167.46532 ...  178.751    178.76084  178.80538]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier()\n\u001b[1;32m----> 2\u001b[0m xgb_model\u001b[38;5;241m.\u001b[39mfit(x,y)\n",
      "File \u001b[1;32mc:\\Users\\alexs\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alexs\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1491\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1488\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1490\u001b[0m ):\n\u001b[1;32m-> 1491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1492\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1493\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1494\u001b[0m     )\n\u001b[0;32m   1496\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [      0       1       2 ... 1469692 1469693 1469694], got [-167.54093 -167.48913 -167.46532 ...  178.751    178.76084  178.80538]"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the last observed values for each vessel\n",
    "def last_observed(df):\n",
    "    last_obs = df.groupby('vesselId').last().reset_index()\n",
    "    return last_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_for_predictions(test, features):\n",
    "    test = test.copy()\n",
    "    features = features.copy()\n",
    "\n",
    "    # Find the last observed values for each vessel\n",
    "    last_obs = last_observed(features)\n",
    "    last_obs = last_obs.drop(columns=['last_longitude', 'last_latitude', 'month', 'day', 'hour', 'minute', 'second']).copy() \n",
    "    \n",
    "    test = pd.merge(test, last_obs, on='vesselId', how='left')\n",
    "\n",
    "    # Rename the columns latitude and longitude to last_latitude and last_longitude\n",
    "    test.rename(columns={'longitude': 'last_longitude', 'latitude': 'last_latitude'}, inplace=True)    \n",
    "\n",
    "    # Fix the time column\n",
    "    test['month'] = test['time'].dt.month\n",
    "    test['day'] = test['time'].dt.day\n",
    "    test['hour'] = test['time'].dt.hour\n",
    "    test['minute'] = test['time'].dt.minute\n",
    "    test['second'] = test['time'].dt.second\n",
    "    test.drop('time', axis=1, inplace=True)\n",
    "\n",
    "    test.drop('scaling_factor', axis=1, inplace=True)\n",
    "    test.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = prepare_test_for_predictions(test,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the Random Forest model\n",
    "predictions = xgb_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the required format\n",
    "predictions_df = pd.DataFrame(predictions, columns=['latitude_predicted', 'longitude_predicted'])\n",
    "predictions_df['ID'] = range(len(predictions_df))\n",
    "predictions_df = predictions_df[['ID', 'longitude_predicted', 'latitude_predicted']]\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('predictions_3.csv', index=False, columns=['ID', 'longitude_predicted', 'latitude_predicted'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
