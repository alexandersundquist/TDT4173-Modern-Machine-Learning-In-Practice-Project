{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 12\n",
    "- LSTM\n",
    "- Kaggle score: 138.27419\n",
    "- Correlating csv file: predictions_12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "### Retrieving data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1522065 entries, 0 to 1522064\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count    Dtype         \n",
      "---  ------     --------------    -----         \n",
      " 0   time       1522065 non-null  datetime64[ns]\n",
      " 1   cog        1522065 non-null  float64       \n",
      " 2   sog        1522065 non-null  float64       \n",
      " 3   rot        1522065 non-null  int64         \n",
      " 4   heading    1522065 non-null  int64         \n",
      " 5   navstat    1522065 non-null  int64         \n",
      " 6   etaRaw     1522065 non-null  object        \n",
      " 7   latitude   1522065 non-null  float64       \n",
      " 8   longitude  1522065 non-null  float64       \n",
      " 9   vesselId   1522065 non-null  object        \n",
      " 10  portId     1520450 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(3), object(3)\n",
      "memory usage: 127.7+ MB\n",
      "Number of missing values in each column:\n",
      " time            0\n",
      "cog             0\n",
      "sog             0\n",
      "rot             0\n",
      "heading         0\n",
      "navstat         0\n",
      "etaRaw          0\n",
      "latitude        0\n",
      "longitude       0\n",
      "vesselId        0\n",
      "portId       1615\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>portId</th>\n",
       "      <th>name</th>\n",
       "      <th>portLocation</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>UN_LOCODE</th>\n",
       "      <th>countryName</th>\n",
       "      <th>ISO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61d36ed80a1807568ff9a064</td>\n",
       "      <td>Port of Algiers</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>3.067222</td>\n",
       "      <td>36.773611</td>\n",
       "      <td>DZALG</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61d36ed80a1807568ff9a065</td>\n",
       "      <td>Port of Annaba</td>\n",
       "      <td>Annaba</td>\n",
       "      <td>7.772500</td>\n",
       "      <td>36.900556</td>\n",
       "      <td>DZAAE</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61d36edf0a1807568ff9a070</td>\n",
       "      <td>Port of Oran</td>\n",
       "      <td>Oran</td>\n",
       "      <td>-0.639722</td>\n",
       "      <td>35.712222</td>\n",
       "      <td>DZORN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61d36ee00a1807568ff9a072</td>\n",
       "      <td>Port of Skikda</td>\n",
       "      <td>Skikda</td>\n",
       "      <td>6.905833</td>\n",
       "      <td>36.887500</td>\n",
       "      <td>DZSKI</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61d36ee10a1807568ff9a074</td>\n",
       "      <td>Port of Pago-Pago</td>\n",
       "      <td>Pago-Pago</td>\n",
       "      <td>-170.690556</td>\n",
       "      <td>-14.274167</td>\n",
       "      <td>ASPPG</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     portId               name portLocation   longitude  \\\n",
       "0  61d36ed80a1807568ff9a064    Port of Algiers      Algiers    3.067222   \n",
       "1  61d36ed80a1807568ff9a065     Port of Annaba       Annaba    7.772500   \n",
       "2  61d36edf0a1807568ff9a070       Port of Oran         Oran   -0.639722   \n",
       "3  61d36ee00a1807568ff9a072     Port of Skikda       Skikda    6.905833   \n",
       "4  61d36ee10a1807568ff9a074  Port of Pago-Pago    Pago-Pago -170.690556   \n",
       "\n",
       "    latitude UN_LOCODE     countryName ISO  \n",
       "0  36.773611     DZALG         Algeria  DZ  \n",
       "1  36.900556     DZAAE         Algeria  DZ  \n",
       "2  35.712222     DZORN         Algeria  DZ  \n",
       "3  36.887500     DZSKI         Algeria  DZ  \n",
       "4 -14.274167     ASPPG  American Samoa  AS  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('ais_train.csv', sep='|')\n",
    "train['time'] = pd.to_datetime(train['time'])\n",
    "train.info()\n",
    "missing_values = train.isnull().sum()\n",
    "print(\"Number of missing values in each column:\\n\", missing_values)\n",
    "\n",
    "train.head()\n",
    "\n",
    "test = pd.read_csv('ais_test.csv', sep=',')\n",
    "test['time'] = pd.to_datetime(test['time'])\n",
    "test.head()\n",
    "\n",
    "vessels = pd.read_csv('vessels.csv', sep='|')\n",
    "vessels.head()\n",
    "\n",
    "ports = pd.read_csv('ports.csv', sep='|')\n",
    "ports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating ID-mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_id_mapping = {port_id: idx for idx, port_id in enumerate(train['portId'].unique())}\n",
    "train['portId'] = train['portId'].map(port_id_mapping)\n",
    "ports['portId'] = ports['portId'].map(port_id_mapping)\n",
    "\n",
    "\n",
    "vessel_id_mapping = {vessel_id: idx for idx, vessel_id in enumerate(train['vesselId'].unique())}\n",
    "train['vesselId'] = train['vesselId'].map(vessel_id_mapping)\n",
    "vessels['vesselId'] = vessels['vesselId'].map(vessel_id_mapping)\n",
    "test['vesselId'] = test['vesselId'].map(vessel_id_mapping)\n",
    "\n",
    "# Create a DataFrame to visualize the vessel ID mapping\n",
    "vessel_id_mapping_df = pd.DataFrame(list(vessel_id_mapping.items()), columns=['Original Vessel ID', 'Mapped Vessel ID'])\n",
    "\n",
    "\n",
    "shipping_line_id_mapping = {shipping_line_id: idx for idx, shipping_line_id in enumerate(vessels['shippingLineId'].unique())}\n",
    "vessels['shippingLineId'] = vessels['shippingLineId'].map(shipping_line_id_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cog</th>\n",
       "      <th>sog</th>\n",
       "      <th>rot</th>\n",
       "      <th>heading</th>\n",
       "      <th>navstat</th>\n",
       "      <th>etaRaw</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>portId</th>\n",
       "      <th>latitude_port</th>\n",
       "      <th>longitude_port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:25</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>01-09 23:00</td>\n",
       "      <td>-34.74370</td>\n",
       "      <td>-57.85130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-33.5875</td>\n",
       "      <td>-71.618889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 00:00:36</td>\n",
       "      <td>109.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>12-29 20:00</td>\n",
       "      <td>8.89440</td>\n",
       "      <td>-79.47939</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9670</td>\n",
       "      <td>-79.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 00:01:45</td>\n",
       "      <td>111.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>01-02 09:00</td>\n",
       "      <td>39.19065</td>\n",
       "      <td>-76.47567</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>39.2325</td>\n",
       "      <td>-76.558889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 00:03:11</td>\n",
       "      <td>96.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>12-31 20:00</td>\n",
       "      <td>-34.41189</td>\n",
       "      <td>151.02067</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-34.4625</td>\n",
       "      <td>150.899444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 00:03:51</td>\n",
       "      <td>214.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>01-25 12:00</td>\n",
       "      <td>35.88379</td>\n",
       "      <td>-5.91636</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>35.7830</td>\n",
       "      <td>-5.817000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    cog   sog  rot  heading  navstat       etaRaw  \\\n",
       "0 2024-01-01 00:00:25  284.0   0.7    0       88        0  01-09 23:00   \n",
       "1 2024-01-01 00:00:36  109.6   0.0   -6      347        1  12-29 20:00   \n",
       "2 2024-01-01 00:01:45  111.0  11.0    0      112        0  01-02 09:00   \n",
       "3 2024-01-01 00:03:11   96.4   0.0    0      142        1  12-31 20:00   \n",
       "4 2024-01-01 00:03:51  214.0  19.7    0      215        0  01-25 12:00   \n",
       "\n",
       "   latitude  longitude  vesselId  portId  latitude_port  longitude_port  \n",
       "0 -34.74370  -57.85130         0       0       -33.5875      -71.618889  \n",
       "1   8.89440  -79.47939         1       1         8.9670      -79.533000  \n",
       "2  39.19065  -76.47567         2       2        39.2325      -76.558889  \n",
       "3 -34.41189  151.02067         3       3       -34.4625      150.899444  \n",
       "4  35.88379   -5.91636         4       4        35.7830       -5.817000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(ports[['portId', 'latitude', 'longitude']], how='left', left_on='portId', right_on='portId', suffixes=('', '_port'))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the five-day-window features\n",
    "\n",
    "def create_five_day_windows(df):\n",
    "    # Ensure that 'time' column is in datetime format\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    \n",
    "    # Sort data to ensure time sequence within each vessel\n",
    "    df = df.sort_values(by=['vesselId', 'time']).reset_index(drop=True)\n",
    "    \n",
    "    window_size_days = 5\n",
    "    windows = []\n",
    "\n",
    "    for vessel_id, group in df.groupby('vesselId'):\n",
    "        group = group.sort_values(by='time')\n",
    "        unique_dates = group['time'].dt.date.unique()\n",
    "\n",
    "        for start_idx in range(len(unique_dates) - window_size_days + 1):\n",
    "            start_date = unique_dates[start_idx]\n",
    "            end_date = unique_dates[start_idx + window_size_days - 1]\n",
    "            window = group[(group['time'].dt.date >= start_date) & (group['time'].dt.date <= end_date)]\n",
    "\n",
    "            # Skip empty windows\n",
    "            if len(window) == 0:\n",
    "                continue\n",
    "\n",
    "            # Reference row: the first row in the window\n",
    "            reference_row = window.iloc[0]\n",
    "\n",
    "            # Append each row in this window with reference features from the first row\n",
    "            for _, row in window.iterrows():\n",
    "                windows.append({\n",
    "                    'vesselId': row['vesselId'],\n",
    "                    'time': row['time'],\n",
    "                    'latitude': row['latitude'],\n",
    "                    'longitude': row['longitude'],\n",
    "                    'cog': row['cog'],\n",
    "                    'sog': row['sog'],\n",
    "                    'rot': row['rot'],\n",
    "                    'under_way': row['under_way'],\n",
    "                    # Features based on the first row in the window\n",
    "                    'latitude_first': reference_row['latitude'],\n",
    "                    'longitude_first': reference_row['longitude'],\n",
    "                    'cog_first': reference_row['cog'],\n",
    "                    'sog_first': reference_row['sog'],\n",
    "                    'rot_first': reference_row['rot'],\n",
    "                    'under_way_first': reference_row['under_way'],\n",
    "                    'time_since_start': (row['time'] - reference_row['time']).total_seconds()\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(windows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features to train the model.\n",
    "def feature_engineering(train):\n",
    "    train = train.copy()\n",
    "\n",
    "    # Sort data to ensure time sequence within each vessel\n",
    "    train = train.sort_values(by=['vesselId', 'time']).reset_index(drop=True)\n",
    "\n",
    "    # Handle NaNs by filling forward then backward within each vessel's data\n",
    "    train[['latitude', 'longitude', 'cog', 'time']] = (\n",
    "        train.groupby('vesselId')[['latitude', 'longitude', 'cog', 'time']].apply(lambda x: x.ffill().bfill())\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    features = pd.DataFrame()\n",
    "    features['vesselId'] = train['vesselId']\n",
    "    features['time'] = train['time']\n",
    "    features['latitude'] = train['latitude']\n",
    "    features['longitude'] = train['longitude']\n",
    "    features['cog'] = train['cog']\n",
    "    features['sog'] = train['sog']\n",
    "    features['rot'] = train['rot']\n",
    "    features['under_way'] = train['navstat'].isin([0, 8]).astype(int)\n",
    "    \n",
    "    # Create five-day sliding windows for each vessel\n",
    "    features = create_five_day_windows(features)\n",
    "    \n",
    "\n",
    "    # Additional time and angle transformations\n",
    "    features['month'] = features['time'].dt.month\n",
    "    features['day'] = features['time'].dt.day\n",
    "    features['hour'] = features['time'].dt.hour\n",
    "    features['minute'] = features['time'].dt.minute\n",
    "\n",
    "    return features\n",
    "\n",
    "train_features = feature_engineering(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vesselId            0\n",
      "time                0\n",
      "latitude            0\n",
      "longitude           0\n",
      "cog                 0\n",
      "sog                 0\n",
      "rot                 0\n",
      "under_way           0\n",
      "latitude_first      0\n",
      "longitude_first     0\n",
      "cog_first           0\n",
      "sog_first           0\n",
      "rot_first           0\n",
      "under_way_first     0\n",
      "time_since_start    0\n",
      "month               0\n",
      "day                 0\n",
      "hour                0\n",
      "minute              0\n",
      "dtype: int64\n",
      "vesselId            0\n",
      "latitude            0\n",
      "longitude           0\n",
      "cog                 0\n",
      "sog                 0\n",
      "under_way           0\n",
      "latitude_first      0\n",
      "longitude_first     0\n",
      "cog_first           0\n",
      "sog_first           0\n",
      "under_way_first     0\n",
      "time_since_start    0\n",
      "month               0\n",
      "day                 0\n",
      "hour                0\n",
      "minute              0\n",
      "dtype: int64\n",
      "   vesselId  latitude  longitude    cog   sog  under_way  latitude_first  \\\n",
      "0         0 -34.74370  -57.85130  284.0   0.7          1        -34.7437   \n",
      "1         0 -35.16787  -56.77210   92.8  14.2          1        -34.7437   \n",
      "2         0 -35.16863  -56.63185   90.5  14.3          1        -34.7437   \n",
      "3         0 -35.16805  -56.53190   88.2  14.3          1        -34.7437   \n",
      "4         0 -35.16715  -56.45306   88.3  12.3          1        -34.7437   \n",
      "\n",
      "   longitude_first  cog_first  sog_first  under_way_first  time_since_start  \\\n",
      "0         -57.8513      284.0        0.7                1               0.0   \n",
      "1         -57.8513      284.0        0.7                1           22123.0   \n",
      "2         -57.8513      284.0        0.7                1           23874.0   \n",
      "3         -57.8513      284.0        0.7                1           25110.0   \n",
      "4         -57.8513      284.0        0.7                1           26131.0   \n",
      "\n",
      "   month  day  hour  minute  \n",
      "0      1    1     0       0  \n",
      "1      1    1     6       9  \n",
      "2      1    1     6      38  \n",
      "3      1    1     6      58  \n",
      "4      1    1     7      15  \n"
     ]
    }
   ],
   "source": [
    "# Making sure the features are as they should be\n",
    "\n",
    "nan_values = train_features.isnull().sum()\n",
    "print(nan_values)\n",
    "\n",
    "# Drop the columns 'time' and 'rot'\n",
    "train_features = train_features.drop(columns=['time', 'rot', 'rot_first'])\n",
    "\n",
    "# Drop the rows with missing values\n",
    "train_features = train_features.dropna().reset_index(drop=True)\n",
    "\n",
    "nan_values = train_features.isnull().sum()\n",
    "print(nan_values)\n",
    "\n",
    "print(train_features.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vesselId</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cog</th>\n",
       "      <th>sog</th>\n",
       "      <th>under_way</th>\n",
       "      <th>latitude_first</th>\n",
       "      <th>longitude_first</th>\n",
       "      <th>cog_first</th>\n",
       "      <th>sog_first</th>\n",
       "      <th>under_way_first</th>\n",
       "      <th>time_since_start</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>34.57936</td>\n",
       "      <td>128.99926</td>\n",
       "      <td>221.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1</td>\n",
       "      <td>47.54253</td>\n",
       "      <td>-122.52499</td>\n",
       "      <td>53.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1340708.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.24460</td>\n",
       "      <td>103.39997</td>\n",
       "      <td>305.1</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1</td>\n",
       "      <td>24.98448</td>\n",
       "      <td>55.06391</td>\n",
       "      <td>81.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2195733.0</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18.13873</td>\n",
       "      <td>-69.74863</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>40.69757</td>\n",
       "      <td>-74.15090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>603974.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>41.64055</td>\n",
       "      <td>143.29942</td>\n",
       "      <td>87.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1</td>\n",
       "      <td>36.84741</td>\n",
       "      <td>125.83660</td>\n",
       "      <td>60.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1</td>\n",
       "      <td>455585.0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>26.58710</td>\n",
       "      <td>121.27831</td>\n",
       "      <td>39.1</td>\n",
       "      <td>12.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.26628</td>\n",
       "      <td>103.85164</td>\n",
       "      <td>341.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>562766.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vesselId  latitude  longitude    cog   sog  under_way  latitude_first  \\\n",
       "0         0  34.57936  128.99926  221.5  15.5          1        47.54253   \n",
       "1         1   1.24460  103.39997  305.1  15.7          1        24.98448   \n",
       "2         2  18.13873  -69.74863  176.0   0.4          1        40.69757   \n",
       "3         3  41.64055  143.29942   87.6  14.4          1        36.84741   \n",
       "4         4  26.58710  121.27831   39.1  12.7          1         1.26628   \n",
       "\n",
       "   longitude_first  cog_first  sog_first  under_way_first  time_since_start  \\\n",
       "0       -122.52499       53.8        0.4                0         1340708.0   \n",
       "1         55.06391       81.6        0.1                0         2195733.0   \n",
       "2        -74.15090        0.0        0.0                0          603974.0   \n",
       "3        125.83660       60.8        9.7                1          455585.0   \n",
       "4        103.85164      341.0        0.0                0          562766.0   \n",
       "\n",
       "   month  day  hour  minute  \n",
       "0      5    1    12      41  \n",
       "1      4   30    10      12  \n",
       "2      5    7    23      59  \n",
       "3      4   26    13      29  \n",
       "4      5    7    12      28  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_last_features(features):\n",
    "    # Assuming that the last row for every vesselId is the most recent\n",
    "    last_features = features.groupby('vesselId').last().reset_index()\n",
    "    return last_features\n",
    "\n",
    "last_features = find_last_features(train_features)\n",
    "last_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target of heading model\n",
    "y = train_features[['latitude', 'longitude']]  \n",
    "X = train_features.drop(columns=['latitude', 'longitude']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/livekrohg/Documents/ML/ml/sklearn-env/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 446us/step - loss: 511.6123\n",
      "Epoch 2/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 439us/step - loss: 264.0109\n",
      "Epoch 3/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 426us/step - loss: 244.5577\n",
      "Epoch 4/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 435us/step - loss: 230.0550\n",
      "Epoch 5/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 435us/step - loss: 218.1269\n",
      "Epoch 6/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 428us/step - loss: 210.3071\n",
      "Epoch 7/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 450us/step - loss: 204.7584\n",
      "Epoch 8/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 433us/step - loss: 198.1794\n",
      "Epoch 9/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 428us/step - loss: 195.3258\n",
      "Epoch 10/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 447us/step - loss: 191.2174\n",
      "Epoch 11/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 435us/step - loss: 188.6822\n",
      "Epoch 12/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 427us/step - loss: 186.2384\n",
      "Epoch 13/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 441us/step - loss: 184.8300\n",
      "Epoch 14/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 420us/step - loss: 182.6572\n",
      "Epoch 15/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 428us/step - loss: 181.4836\n",
      "Epoch 16/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 428us/step - loss: 180.4551\n",
      "Epoch 17/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 453us/step - loss: 178.7502\n",
      "Epoch 18/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 451us/step - loss: 177.7803\n",
      "Epoch 19/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 439us/step - loss: 176.9522\n",
      "Epoch 20/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 432us/step - loss: 175.8944\n",
      "Epoch 21/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 419us/step - loss: 174.8583\n",
      "Epoch 22/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 439us/step - loss: 174.1767\n",
      "Epoch 23/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 427us/step - loss: 172.8618\n",
      "Epoch 24/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 447us/step - loss: 172.0554\n",
      "Epoch 25/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 434us/step - loss: 170.8201\n",
      "Epoch 26/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 459us/step - loss: 170.5494\n",
      "Epoch 27/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 446us/step - loss: 169.6954\n",
      "Epoch 28/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 443us/step - loss: 169.2074\n",
      "Epoch 29/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 425us/step - loss: 168.5527\n",
      "Epoch 30/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 449us/step - loss: 167.8802\n",
      "Epoch 31/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 438us/step - loss: 166.8680\n",
      "Epoch 32/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 463us/step - loss: 167.2029\n",
      "Epoch 33/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 446us/step - loss: 166.0896\n",
      "Epoch 34/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 468us/step - loss: 165.7715\n",
      "Epoch 35/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 445us/step - loss: 165.1114\n",
      "Epoch 36/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 456us/step - loss: 164.3537\n",
      "Epoch 37/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 451us/step - loss: 164.4456\n",
      "Epoch 38/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 450us/step - loss: 163.9956\n",
      "Epoch 39/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 440us/step - loss: 164.0293\n",
      "Epoch 40/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 449us/step - loss: 163.2777\n",
      "Epoch 41/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 455us/step - loss: 163.0425\n",
      "Epoch 42/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 452us/step - loss: 162.5994\n",
      "Epoch 43/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 439us/step - loss: 162.7026\n",
      "Epoch 44/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 461us/step - loss: 161.8118\n",
      "Epoch 45/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 438us/step - loss: 161.3504\n",
      "Epoch 46/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 467us/step - loss: 161.8844\n",
      "Epoch 47/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 432us/step - loss: 160.4806\n",
      "Epoch 48/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 467us/step - loss: 159.4943\n",
      "Epoch 49/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 449us/step - loss: 160.0121\n",
      "Epoch 50/50\n",
      "\u001b[1m224829/224829\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 463us/step - loss: 160.0212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x454857610>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "X_scaled = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_scaled.shape[1], X_scaled.shape[2])))\n",
    "model.add(Dense(2))  # Output layer with 2 neurons for latitude and longitude\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_scaled, y, epochs=50, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing test data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vesselId', 'cog', 'sog', 'under_way', 'latitude_first',\n",
      "       'longitude_first', 'cog_first', 'sog_first', 'under_way_first',\n",
      "       'time_since_start', 'month', 'day', 'hour', 'minute'],\n",
      "      dtype='object')\n",
      "   vesselId                time  latitude  longitude    cog   sog  under_way  \\\n",
      "0       412 2024-05-08 00:03:16  31.14647  -81.49789  179.6   0.0          0   \n",
      "1       373 2024-05-08 00:06:17  14.81694  120.29625   24.7   0.0          0   \n",
      "2       181 2024-05-08 00:10:02  38.27895   10.78280    8.0  18.7          1   \n",
      "3         8 2024-05-08 00:10:34 -43.53785  172.83522  321.3   0.1          0   \n",
      "4        65 2024-05-08 00:12:27  48.53320   -6.12003  291.0   0.3          0   \n",
      "\n",
      "   latitude_first  longitude_first  cog_first  sog_first  under_way_first  \\\n",
      "0        30.93466        -81.08673      159.0        0.0                0   \n",
      "1        35.44624        139.71653       82.7        0.0                0   \n",
      "2        38.00859         11.68428       40.0       18.7                1   \n",
      "3       -36.84159        174.76965       31.0        0.0                0   \n",
      "4        49.47290          0.18520       28.0        0.0                0   \n",
      "\n",
      "   time_since_start  month  day  hour  minute  year           time_last  \n",
      "0          516824.0      5    7    23      48  2024 2024-05-07 23:48:00  \n",
      "1          776687.0      5    7    23      57  2024 2024-05-07 23:57:00  \n",
      "2          426241.0      5    7    23      59  2024 2024-05-07 23:59:00  \n",
      "3          430552.0      5    7    23      52  2024 2024-05-07 23:52:00  \n",
      "4          430370.0      5    7    23      51  2024 2024-05-07 23:51:00  \n",
      "   vesselId    cog   sog  under_way  latitude_first  longitude_first  \\\n",
      "0       412  179.6   0.0          0        31.14647        -81.49789   \n",
      "1       373   24.7   0.0          0        14.81694        120.29625   \n",
      "2       181    8.0  18.7          1        38.27895         10.78280   \n",
      "3         8  321.3   0.1          0       -43.53785        172.83522   \n",
      "4        65  291.0   0.3          0        48.53320         -6.12003   \n",
      "\n",
      "   cog_first  sog_first  under_way_first  time_since_start  month  day  hour  \\\n",
      "0      179.6        0.0                0             916.0      5    8     0   \n",
      "1       24.7        0.0                0             557.0      5    8     0   \n",
      "2        8.0       18.7                1             662.0      5    8     0   \n",
      "3      321.3        0.1                0            1114.0      5    8     0   \n",
      "4      291.0        0.3                0            1287.0      5    8     0   \n",
      "\n",
      "   minute  \n",
      "0       3  \n",
      "1       6  \n",
      "2      10  \n",
      "3      10  \n",
      "4      12  \n",
      "(51739, 14)\n"
     ]
    }
   ],
   "source": [
    "print(X.keys())\n",
    "'''\n",
    "['vesselId', 'cog', 'sog', 'under_way', 'latitude_first',\n",
    "       'longitude_first', 'cog_first', 'sog_first', 'under_way_first',\n",
    "       'time_since_start', 'month', 'day', 'hour', 'minute']\n",
    "'''\n",
    "\n",
    "### Prepare test data for predictions\n",
    "def prepare_test_for_predictions(test, last_features):\n",
    "    test = test.copy()\n",
    "    prepared_test = pd.DataFrame()\n",
    "\n",
    "    # Create a time column in last features\n",
    "    last_features['year'] = 2024\n",
    "    last_features['time'] = pd.to_datetime(\n",
    "        last_features[['year', 'month', 'day', 'hour', 'minute']]\n",
    "    )\n",
    "\n",
    "    # Add the columns vesselId and time\n",
    "    prepared_test['vesselId'] = test['vesselId']\n",
    "    prepared_test['time'] = test['time']\n",
    "\n",
    "    # For each vessel, add the last seen features to the prepared test\n",
    "    prepared_test = prepared_test.merge(last_features, on='vesselId', how='left', suffixes=('', '_last'))\n",
    "\n",
    "    print(prepared_test.head())\n",
    "\n",
    "    # Move the last_features to the refrence row in the windows\n",
    "    prepared_test['latitude_first'] = prepared_test['latitude']\n",
    "    prepared_test['longitude_first'] = prepared_test['longitude']\n",
    "    prepared_test['cog_first'] = prepared_test['cog']\n",
    "    prepared_test['sog_first'] = prepared_test['sog']\n",
    "    prepared_test['under_way_first'] = prepared_test['under_way']\n",
    "    prepared_test['time_since_start'] = (prepared_test['time'] - prepared_test['time_last']).dt.total_seconds()\n",
    "\n",
    "    # Split the time column into month, day, hour, minute and second columns\n",
    "    prepared_test['month'] = test['time'].dt.month\n",
    "    prepared_test['day'] = test['time'].dt.day\n",
    "    prepared_test['hour'] = test['time'].dt.hour\n",
    "    prepared_test['minute'] = test['time'].dt.minute\n",
    "    # prepared_test['second'] = test['time'].dt.second\n",
    "\n",
    "    prepared_test.drop('time', axis=1, inplace=True)\n",
    "    prepared_test.drop('time_last', axis=1, inplace=True)\n",
    "    prepared_test.drop('year', axis=1, inplace=True)\n",
    "\n",
    "    # Reorder the columns\n",
    "    prepared_test = prepared_test[['vesselId', 'cog', 'sog', 'under_way',\n",
    "                                   'latitude_first', 'longitude_first', 'cog_first', 'sog_first',\n",
    "                                     'under_way_first', 'time_since_start', 'month', 'day',\n",
    "                                   'hour', 'minute']]\n",
    "\n",
    "    return prepared_test\n",
    "\n",
    "test_df = prepare_test_for_predictions(test, last_features)\n",
    "print(test_df.head())\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the trained model and corresponding scaler to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler12.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model.save('LSTM12.keras')  # Save the model\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'scaler12.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1617/1617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257us/step\n",
      "[[  32.00753    -83.24888  ]\n",
      " [  12.202564   127.922905 ]\n",
      " [  43.05332      8.9681015]\n",
      " ...\n",
      " [  44.643593  -138.83044  ]\n",
      " [  51.104652    21.17188  ]\n",
      " [  54.434044    -2.3198915]]\n",
      "(51739, 2)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "test_df_scaled = scaler.transform(test_df)\n",
    "test_df_scaled = test_df_scaled.reshape((test_df_scaled.shape[0], 1, test_df_scaled.shape[1]))\n",
    "predictions = model.predict(test_df_scaled)\n",
    "\n",
    "print(predictions)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the required format\n",
    "predictions_df = pd.DataFrame(predictions, columns=['latitude_predicted', 'longitude_predicted'])\n",
    "predictions_df['ID'] = range(len(predictions_df))\n",
    "predictions_df = predictions_df[['ID', 'longitude_predicted', 'latitude_predicted']]\n",
    "\n",
    "# Save to CSV\n",
    "predictions_df.to_csv('predictions_12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
