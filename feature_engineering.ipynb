{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_train = pd.read_csv('ais_train.csv', sep='|')\n",
    "ports = pd.read_csv('ports.csv', sep='|')\n",
    "vessels = pd.read_csv('vessels.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cog   sog  rot  navstat  latitude_x  longitude_x  \\\n",
      "0  284.0   0.7    0        0   -34.74370    -57.85130   \n",
      "1  109.6   0.0   -6        1     8.89440    -79.47939   \n",
      "2  111.0  11.0    0        0    39.19065    -76.47567   \n",
      "3   96.4   0.0    0        1   -34.41189    151.02067   \n",
      "4  214.0  19.7    0        0    35.88379     -5.91636   \n",
      "\n",
      "                   vesselId                    portId  longitude_y  \\\n",
      "0  61e9f3a8b937134a3c4bfdf7  61d371c43aeaecc07011a37f   -71.618889   \n",
      "1  61e9f3d4b937134a3c4bff1f  634c4de270937fc01c3a7689   -79.533000   \n",
      "2  61e9f436b937134a3c4c0131  61d3847bb7b7526e1adf3d19   -76.558889   \n",
      "3  61e9f3b4b937134a3c4bfe77  61d36f770a1807568ff9a126   150.899444   \n",
      "4  61e9f41bb937134a3c4c0087  634c4de270937fc01c3a74f3    -5.817000   \n",
      "\n",
      "   latitude_y  ... etaMonth  etaDay  etaHour  etaMinute timeYear  timeMonth  \\\n",
      "0    -33.5875  ...        1       9       23          0       24          1   \n",
      "1      8.9670  ...       12      29       20          0       24          1   \n",
      "2     39.2325  ...        1       2        9          0       24          1   \n",
      "3    -34.4625  ...       12      31       20          0       24          1   \n",
      "4     35.7830  ...        1      25       12          0       24          1   \n",
      "\n",
      "   timeDay  timeHour  timeMinute  timeSecond  \n",
      "0        1         0           0          25  \n",
      "1        1         0           0          36  \n",
      "2        1         0           1          45  \n",
      "3        1         0           3          11  \n",
      "4        1         0           3          51  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "def preprocess(ais_train, ports, vessels):\n",
    "    ais_data = ais_train.copy()\n",
    "    ports_data = ports.copy()\n",
    "    vessels_data = vessels.copy()\n",
    "\n",
    "    # Remove the rows in ais_data that does not contain a portId\n",
    "    ais_data = ais_data[ais_data['portId'].notnull()]\n",
    "\n",
    "    # Removing unwanted columns\n",
    "    ais_data.drop(columns=['heading'], inplace=True)\n",
    "    ports_data.drop(columns=['name', 'portLocation', 'UN_LOCODE', 'countryName', 'ISO'], inplace=True)\n",
    "    vessels_data.drop(columns=['DWT', 'NT', 'vesselType', 'depth', 'draft', 'enginePower', 'freshWater', 'fuel', 'maxHeight', 'maxSpeed', 'maxWidth', 'rampCapacity', 'yearBuilt'], inplace=True)\n",
    "\n",
    "    # Merging ais_data with ports_data on portId\n",
    "    data = pd.merge(ais_data, ports_data, on='portId', how='left')\n",
    "\n",
    "    # Merging data with vessels_data on vesselId\n",
    "    data = pd.merge(data, vessels_data, on='vesselId', how='left')\n",
    "\n",
    "    # Ensure 'etaRaw' and 'time' columns are strings\n",
    "    data['etaRaw'] = data['etaRaw'].astype(str)\n",
    "    data['time'] = data['time'].astype(str)\n",
    "\n",
    "    # Extract calendar features for 'etaRaw'\n",
    "    data[['etaMonth', 'etaDay', 'etaHour', 'etaMinute']] = data['etaRaw'].str.extract(r'(\\d{2})-(\\d{2}) (\\d{2}):(\\d{2})')\n",
    "\n",
    "    # Extract calendar features for 'time'\n",
    "    data[['timeYear', 'timeMonth', 'timeDay', 'timeHour', 'timeMinute', 'timeSecond']] = data['time'].str.extract(r'(\\d{2})-(\\d{2})-(\\d{2}) (\\d{2}):(\\d{2}):(\\d{2})')\n",
    "\n",
    "    # Convert objects to integers\n",
    "    data[['etaMonth', 'etaDay', 'etaHour', 'etaMinute', 'timeYear', 'timeMonth', 'timeDay', 'timeHour', 'timeMinute', 'timeSecond']] = data[['etaMonth', 'etaDay', 'etaHour', 'etaMinute', 'timeYear', 'timeMonth', 'timeDay', 'timeHour', 'timeMinute', 'timeSecond']].astype(int)\n",
    "\n",
    "    # Drop time and etaRaw columns\n",
    "    data.drop(columns=['time', 'etaRaw'], inplace=True)\n",
    "\n",
    "    # Removing sog outliers \n",
    "    data = data[data['sog'] <= 40]\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = preprocess(ais_train, ports, vessels)\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cog   sog  rot  latitude_x  longitude_x                   vesselId  \\\n",
      "142   73.9   0.1   12   -26.77586    153.23453   61e9f3acb937134a3c4bfe23   \n",
      "144  150.7   0.1    0    38.47387     15.91592   61e9f3cab937134a3c4bff01   \n",
      "145   56.4  12.9  -16    33.90815    130.92404   61e9f3e1b937134a3c4bff59   \n",
      "147  114.5   0.0    0    43.44237     -3.82309  clh6aqawa0002gh0zypfa5dut   \n",
      "148  210.4   0.0   -5    40.68658     29.31613   61e9f3c7b937134a3c4bfedf   \n",
      "\n",
      "                       portId  longitude_y  latitude_y  \\\n",
      "142  61d36f640a1807568ff9a103   153.169444  -27.382500   \n",
      "144  61d3781393c6feb83e5eb73d    15.904444   38.456667   \n",
      "145  61d37a591366c3998241d986   126.383056   34.776111   \n",
      "147  61d37fb929b60f6113c89ea0    -3.807778   43.442222   \n",
      "148  61d38259b7b7526e1adf3a41    29.841944   40.751111   \n",
      "\n",
      "               shippingLineId  ...  timeMonth  timeDay  timeHour timeMinute  \\\n",
      "142  61a8e672f9cba188601e84ab  ...          1        1         0         17   \n",
      "144  61ec6303a8cafc0e93f0e8f3  ...          1        1         0         18   \n",
      "145  61be24564ea00ae59d0fe37a  ...          1        1         0         19   \n",
      "147  61a8e673f9cba188601e84b3  ...          1        1         0         20   \n",
      "148  61ec6303a8cafc0e93f0e8f3  ...          1        1         0         21   \n",
      "\n",
      "     timeSecond  is_moored  is_anchor  is_moving     distance  \\\n",
      "142          17          0          1          0    33.916839   \n",
      "144          57          0          0          1     2.617928   \n",
      "145          39          0          0          1  2085.388109   \n",
      "147          35          1          0          0     5.774634   \n",
      "148          37          0          1          0    25.430750   \n",
      "\n",
      "     distance_to_port  \n",
      "142      67527.882768  \n",
      "144       2156.338184  \n",
      "145     428734.961148  \n",
      "147       1239.671493  \n",
      "148      45001.070934  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Add NAVSTAT info\n",
    "    df['is_moored'] = df['navstat'].apply(lambda x: 1 if x == 5 else 0)\n",
    "    df['is_anchor'] = df['navstat'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    df['is_moving'] = df['navstat'].apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "    df.drop(columns=['navstat'], inplace=True)\n",
    "    \n",
    "    # Group by vesselId and apply shift\n",
    "    df['latitude_shifted'] = df.groupby('vesselId')['latitude_x'].shift()\n",
    "    df['longitude_shifted'] = df.groupby('vesselId')['longitude_x'].shift()\n",
    "\n",
    "    # Drop rows with NaN values in latitude and longitude columns\n",
    "    df.dropna(subset=['latitude_x', 'longitude_x', 'latitude_y', 'longitude_y', 'latitude_shifted', 'longitude_shifted'], inplace=True)\n",
    "\n",
    "    # Calculate the distance between the current and previous location\n",
    "    df['distance'] = df.apply(lambda x: geodesic((x['latitude_x'], x['longitude_x']), (x['latitude_shifted'], x['longitude_shifted'])).meters, axis=1)\n",
    "\n",
    "    # Drop the shifted columns\n",
    "    df.drop(columns=['latitude_shifted', 'longitude_shifted'], inplace=True)\n",
    "\n",
    "    # Add distance to port\n",
    "    df['distance_to_port'] = df.apply(lambda x: geodesic((x['latitude_x'], x['longitude_x']), (x['latitude_y'], x['longitude_y'])).meters, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "features = feature_engineering(data)\n",
    "print(features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
