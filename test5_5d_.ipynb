{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1522065 entries, 0 to 1522064\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count    Dtype         \n",
      "---  ------     --------------    -----         \n",
      " 0   time       1522065 non-null  datetime64[ns]\n",
      " 1   cog        1522065 non-null  float64       \n",
      " 2   sog        1522065 non-null  float64       \n",
      " 3   rot        1522065 non-null  int64         \n",
      " 4   heading    1522065 non-null  int64         \n",
      " 5   navstat    1522065 non-null  int64         \n",
      " 6   etaRaw     1522065 non-null  object        \n",
      " 7   latitude   1522065 non-null  float64       \n",
      " 8   longitude  1522065 non-null  float64       \n",
      " 9   vesselId   1522065 non-null  object        \n",
      " 10  portId     1520450 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(3), object(3)\n",
      "memory usage: 127.7+ MB\n",
      "Number of missing values in each column:\n",
      " time            0\n",
      "cog             0\n",
      "sog             0\n",
      "rot             0\n",
      "heading         0\n",
      "navstat         0\n",
      "etaRaw          0\n",
      "latitude        0\n",
      "longitude       0\n",
      "vesselId        0\n",
      "portId       1615\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>portId</th>\n",
       "      <th>name</th>\n",
       "      <th>portLocation</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>UN_LOCODE</th>\n",
       "      <th>countryName</th>\n",
       "      <th>ISO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61d36ed80a1807568ff9a064</td>\n",
       "      <td>Port of Algiers</td>\n",
       "      <td>Algiers</td>\n",
       "      <td>3.067222</td>\n",
       "      <td>36.773611</td>\n",
       "      <td>DZALG</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61d36ed80a1807568ff9a065</td>\n",
       "      <td>Port of Annaba</td>\n",
       "      <td>Annaba</td>\n",
       "      <td>7.772500</td>\n",
       "      <td>36.900556</td>\n",
       "      <td>DZAAE</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61d36edf0a1807568ff9a070</td>\n",
       "      <td>Port of Oran</td>\n",
       "      <td>Oran</td>\n",
       "      <td>-0.639722</td>\n",
       "      <td>35.712222</td>\n",
       "      <td>DZORN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61d36ee00a1807568ff9a072</td>\n",
       "      <td>Port of Skikda</td>\n",
       "      <td>Skikda</td>\n",
       "      <td>6.905833</td>\n",
       "      <td>36.887500</td>\n",
       "      <td>DZSKI</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61d36ee10a1807568ff9a074</td>\n",
       "      <td>Port of Pago-Pago</td>\n",
       "      <td>Pago-Pago</td>\n",
       "      <td>-170.690556</td>\n",
       "      <td>-14.274167</td>\n",
       "      <td>ASPPG</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     portId               name portLocation   longitude  \\\n",
       "0  61d36ed80a1807568ff9a064    Port of Algiers      Algiers    3.067222   \n",
       "1  61d36ed80a1807568ff9a065     Port of Annaba       Annaba    7.772500   \n",
       "2  61d36edf0a1807568ff9a070       Port of Oran         Oran   -0.639722   \n",
       "3  61d36ee00a1807568ff9a072     Port of Skikda       Skikda    6.905833   \n",
       "4  61d36ee10a1807568ff9a074  Port of Pago-Pago    Pago-Pago -170.690556   \n",
       "\n",
       "    latitude UN_LOCODE     countryName ISO  \n",
       "0  36.773611     DZALG         Algeria  DZ  \n",
       "1  36.900556     DZAAE         Algeria  DZ  \n",
       "2  35.712222     DZORN         Algeria  DZ  \n",
       "3  36.887500     DZSKI         Algeria  DZ  \n",
       "4 -14.274167     ASPPG  American Samoa  AS  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/datasets/ais_train.csv', sep='|')\n",
    "train['time'] = pd.to_datetime(train['time'])\n",
    "train.info()\n",
    "missing_values = train.isnull().sum()\n",
    "print(\"Number of missing values in each column:\\n\", missing_values)\n",
    "\n",
    "\n",
    "train.head()\n",
    "\n",
    "test = pd.read_csv('data/datasets/ais_test.csv', sep=',')\n",
    "test['time'] = pd.to_datetime(test['time'])\n",
    "test.head()\n",
    "\n",
    "vessels = pd.read_csv('data/datasets/vessels.csv', sep='|')\n",
    "vessels.head()\n",
    "\n",
    "ports = pd.read_csv('data/datasets/ports.csv', sep='|')\n",
    "ports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_id_mapping = {port_id: idx for idx, port_id in enumerate(train['portId'].unique())}\n",
    "train['portId'] = train['portId'].map(port_id_mapping)\n",
    "ports['portId'] = ports['portId'].map(port_id_mapping)\n",
    "\n",
    "vessel_id_mapping = {vessel_id: idx for idx, vessel_id in enumerate(train['vesselId'].unique())}\n",
    "train['vesselId'] = train['vesselId'].map(vessel_id_mapping)\n",
    "vessels['vesselId'] = vessels['vesselId'].map(vessel_id_mapping)\n",
    "test['vesselId'] = test['vesselId'].map(vessel_id_mapping)\n",
    "\n",
    "shipping_line_id_mapping = {shipping_line_id: idx for idx, shipping_line_id in enumerate(vessels['shippingLineId'].unique())}\n",
    "vessels['shippingLineId'] = vessels['shippingLineId'].map(shipping_line_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shippingLineId</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>CEU</th>\n",
       "      <th>DWT</th>\n",
       "      <th>GT</th>\n",
       "      <th>NT</th>\n",
       "      <th>vesselType</th>\n",
       "      <th>breadth</th>\n",
       "      <th>depth</th>\n",
       "      <th>draft</th>\n",
       "      <th>enginePower</th>\n",
       "      <th>freshWater</th>\n",
       "      <th>fuel</th>\n",
       "      <th>homePort</th>\n",
       "      <th>length</th>\n",
       "      <th>maxHeight</th>\n",
       "      <th>maxSpeed</th>\n",
       "      <th>maxWidth</th>\n",
       "      <th>rampCapacity</th>\n",
       "      <th>yearBuilt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>6500</td>\n",
       "      <td>21200.0</td>\n",
       "      <td>58684</td>\n",
       "      <td>17606.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OSLO</td>\n",
       "      <td>199.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>15.2</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4902</td>\n",
       "      <td>12325.0</td>\n",
       "      <td>46800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MONROVIA</td>\n",
       "      <td>182.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>640.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>13059.0</td>\n",
       "      <td>46800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAINT JOHN'S</td>\n",
       "      <td>182.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>255.0</td>\n",
       "      <td>4200</td>\n",
       "      <td>12588.0</td>\n",
       "      <td>39362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11060.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7450</td>\n",
       "      <td>21052.0</td>\n",
       "      <td>75528</td>\n",
       "      <td>24391.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>22.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13140.0</td>\n",
       "      <td>491.47</td>\n",
       "      <td>3236.78</td>\n",
       "      <td>Panama</td>\n",
       "      <td>199.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shippingLineId  vesselId   CEU      DWT     GT       NT  vesselType  \\\n",
       "0               0     599.0  6500  21200.0  58684  17606.0        83.0   \n",
       "1               1      65.0  4902  12325.0  46800      NaN        83.0   \n",
       "2               2     640.0  5000  13059.0  46800      NaN        83.0   \n",
       "3               3     255.0  4200  12588.0  39362      NaN        83.0   \n",
       "4               4      68.0  7450  21052.0  75528  24391.0        83.0   \n",
       "\n",
       "   breadth  depth  draft  enginePower  freshWater     fuel      homePort  \\\n",
       "0     32.0  22.20    NaN          0.0         NaN      NaN          OSLO   \n",
       "1     31.0    NaN    NaN      14220.0         NaN      NaN      MONROVIA   \n",
       "2     31.0    NaN    NaN      14220.0         NaN      NaN  SAINT JOHN'S   \n",
       "3     28.0    NaN    NaN      11060.0         NaN      NaN           NaN   \n",
       "4     37.2  22.23    NaN      13140.0      491.47  3236.78        Panama   \n",
       "\n",
       "   length  maxHeight  maxSpeed  maxWidth  rampCapacity  yearBuilt  \n",
       "0  199.00        5.0      18.6      15.2         150.0       2000  \n",
       "1  182.00        NaN       NaN       NaN           NaN       2006  \n",
       "2  182.00        NaN       NaN       NaN           NaN       2010  \n",
       "3  167.00        NaN       NaN       NaN           NaN       2011  \n",
       "4  199.98        NaN       NaN       NaN           NaN       2018  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vessels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cog</th>\n",
       "      <th>sog</th>\n",
       "      <th>rot</th>\n",
       "      <th>heading</th>\n",
       "      <th>navstat</th>\n",
       "      <th>etaRaw</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>portId</th>\n",
       "      <th>latitude_port</th>\n",
       "      <th>longitude_port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:25</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>01-09 23:00</td>\n",
       "      <td>-34.74370</td>\n",
       "      <td>-57.85130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-33.5875</td>\n",
       "      <td>-71.618889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 00:00:36</td>\n",
       "      <td>109.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>12-29 20:00</td>\n",
       "      <td>8.89440</td>\n",
       "      <td>-79.47939</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9670</td>\n",
       "      <td>-79.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 00:01:45</td>\n",
       "      <td>111.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>01-02 09:00</td>\n",
       "      <td>39.19065</td>\n",
       "      <td>-76.47567</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>39.2325</td>\n",
       "      <td>-76.558889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 00:03:11</td>\n",
       "      <td>96.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>12-31 20:00</td>\n",
       "      <td>-34.41189</td>\n",
       "      <td>151.02067</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-34.4625</td>\n",
       "      <td>150.899444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 00:03:51</td>\n",
       "      <td>214.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>01-25 12:00</td>\n",
       "      <td>35.88379</td>\n",
       "      <td>-5.91636</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>35.7830</td>\n",
       "      <td>-5.817000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    cog   sog  rot  heading  navstat       etaRaw  \\\n",
       "0 2024-01-01 00:00:25  284.0   0.7    0       88        0  01-09 23:00   \n",
       "1 2024-01-01 00:00:36  109.6   0.0   -6      347        1  12-29 20:00   \n",
       "2 2024-01-01 00:01:45  111.0  11.0    0      112        0  01-02 09:00   \n",
       "3 2024-01-01 00:03:11   96.4   0.0    0      142        1  12-31 20:00   \n",
       "4 2024-01-01 00:03:51  214.0  19.7    0      215        0  01-25 12:00   \n",
       "\n",
       "   latitude  longitude  vesselId  portId  latitude_port  longitude_port  \n",
       "0 -34.74370  -57.85130         0       0       -33.5875      -71.618889  \n",
       "1   8.89440  -79.47939         1       1         8.9670      -79.533000  \n",
       "2  39.19065  -76.47567         2       2        39.2325      -76.558889  \n",
       "3 -34.41189  151.02067         3       3       -34.4625      150.899444  \n",
       "4  35.88379   -5.91636         4       4        35.7830       -5.817000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train = train.merge(ports[['portId', 'latitude', 'longitude']], how='left', left_on='portId', right_on='portId', suffixes=('', '_port'))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in maxSpeed: 14949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cog</th>\n",
       "      <th>sog</th>\n",
       "      <th>rot</th>\n",
       "      <th>heading</th>\n",
       "      <th>navstat</th>\n",
       "      <th>etaRaw</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>portId</th>\n",
       "      <th>latitude_port</th>\n",
       "      <th>longitude_port</th>\n",
       "      <th>length</th>\n",
       "      <th>shippingLineId</th>\n",
       "      <th>breadth</th>\n",
       "      <th>GT</th>\n",
       "      <th>vessel_deep_sea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:25</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>01-09 23:00</td>\n",
       "      <td>-34.74370</td>\n",
       "      <td>-57.85130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-33.5875</td>\n",
       "      <td>-71.618889</td>\n",
       "      <td>199.00</td>\n",
       "      <td>9</td>\n",
       "      <td>32.00</td>\n",
       "      <td>57718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 00:00:36</td>\n",
       "      <td>109.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>12-29 20:00</td>\n",
       "      <td>8.89440</td>\n",
       "      <td>-79.47939</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9670</td>\n",
       "      <td>-79.533000</td>\n",
       "      <td>199.97</td>\n",
       "      <td>6</td>\n",
       "      <td>32.26</td>\n",
       "      <td>59583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 00:01:45</td>\n",
       "      <td>111.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>01-02 09:00</td>\n",
       "      <td>39.19065</td>\n",
       "      <td>-76.47567</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>39.2325</td>\n",
       "      <td>-76.558889</td>\n",
       "      <td>199.00</td>\n",
       "      <td>14</td>\n",
       "      <td>32.00</td>\n",
       "      <td>59217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 00:03:11</td>\n",
       "      <td>96.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>12-31 20:00</td>\n",
       "      <td>-34.41189</td>\n",
       "      <td>151.02067</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-34.4625</td>\n",
       "      <td>150.899444</td>\n",
       "      <td>199.00</td>\n",
       "      <td>5</td>\n",
       "      <td>32.00</td>\n",
       "      <td>55598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 00:03:51</td>\n",
       "      <td>214.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>01-25 12:00</td>\n",
       "      <td>35.88379</td>\n",
       "      <td>-5.91636</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>35.7830</td>\n",
       "      <td>-5.817000</td>\n",
       "      <td>199.95</td>\n",
       "      <td>6</td>\n",
       "      <td>32.20</td>\n",
       "      <td>58939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    cog   sog  rot  heading  navstat       etaRaw  \\\n",
       "0 2024-01-01 00:00:25  284.0   0.7    0       88        0  01-09 23:00   \n",
       "1 2024-01-01 00:00:36  109.6   0.0   -6      347        1  12-29 20:00   \n",
       "2 2024-01-01 00:01:45  111.0  11.0    0      112        0  01-02 09:00   \n",
       "3 2024-01-01 00:03:11   96.4   0.0    0      142        1  12-31 20:00   \n",
       "4 2024-01-01 00:03:51  214.0  19.7    0      215        0  01-25 12:00   \n",
       "\n",
       "   latitude  longitude  vesselId  portId  latitude_port  longitude_port  \\\n",
       "0 -34.74370  -57.85130         0       0       -33.5875      -71.618889   \n",
       "1   8.89440  -79.47939         1       1         8.9670      -79.533000   \n",
       "2  39.19065  -76.47567         2       2        39.2325      -76.558889   \n",
       "3 -34.41189  151.02067         3       3       -34.4625      150.899444   \n",
       "4  35.88379   -5.91636         4       4        35.7830       -5.817000   \n",
       "\n",
       "   length  shippingLineId  breadth     GT  vessel_deep_sea  \n",
       "0  199.00               9    32.00  57718                0  \n",
       "1  199.97               6    32.26  59583                0  \n",
       "2  199.00              14    32.00  59217                0  \n",
       "3  199.00               5    32.00  55598                0  \n",
       "4  199.95               6    32.20  58939                0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(vessels[['vesselId', 'length', 'shippingLineId', 'breadth', 'GT']], on='vesselId', how='left')\n",
    "train['vessel_deep_sea'] = np.where(train['length'] > 200, 1, 0)\n",
    "\n",
    "num_maxSpeed_nan = train['breadth'].isna().sum()\n",
    "print(f\"Number of NaN values in maxSpeed: {num_maxSpeed_nan}\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Breadth values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean breadth for shipping line 5\n",
    "mean_breadth_shipping_line_5 = train[train['shippingLineId'] == 5]['breadth'].mean()\n",
    "\n",
    "# Impute missing breadth with the calculated mean\n",
    "train.loc[train['shippingLineId'] == 5, 'breadth'] = train.loc[train['shippingLineId'] == 5, 'breadth'].fillna(mean_breadth_shipping_line_5)\n",
    "\n",
    "# Verify if the missing values were filled\n",
    "missing_count_after_imputation = train['breadth'].isnull().sum()\n",
    "print(f\"Missing Breadth values after imputation: {missing_count_after_imputation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1522065 entries, 0 to 1522064\n",
      "Data columns (total 18 columns):\n",
      " #   Column           Non-Null Count    Dtype         \n",
      "---  ------           --------------    -----         \n",
      " 0   time             1522065 non-null  datetime64[ns]\n",
      " 1   cog              1522065 non-null  float64       \n",
      " 2   sog              1522065 non-null  float64       \n",
      " 3   rot              1522065 non-null  int64         \n",
      " 4   heading          1522065 non-null  int64         \n",
      " 5   navstat          1522065 non-null  int64         \n",
      " 6   etaRaw           1522065 non-null  object        \n",
      " 7   latitude         1522065 non-null  float64       \n",
      " 8   longitude        1522065 non-null  float64       \n",
      " 9   vesselId         1522065 non-null  int64         \n",
      " 10  portId           1522065 non-null  int64         \n",
      " 11  latitude_port    1520450 non-null  float64       \n",
      " 12  longitude_port   1520450 non-null  float64       \n",
      " 13  length           1522065 non-null  float64       \n",
      " 14  shippingLineId   1522065 non-null  int64         \n",
      " 15  breadth          1522065 non-null  float64       \n",
      " 16  GT               1522065 non-null  int64         \n",
      " 17  vessel_deep_sea  1522065 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(8), int64(8), object(1)\n",
      "memory usage: 209.0+ MB\n",
      "Number of missing values in each column:\n",
      " time                  0\n",
      "cog                   0\n",
      "sog                   0\n",
      "rot                   0\n",
      "heading               0\n",
      "navstat               0\n",
      "etaRaw                0\n",
      "latitude              0\n",
      "longitude             0\n",
      "vesselId              0\n",
      "portId                0\n",
      "latitude_port      1615\n",
      "longitude_port     1615\n",
      "length                0\n",
      "shippingLineId        0\n",
      "breadth               0\n",
      "GT                    0\n",
      "vessel_deep_sea       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "missing_values = train.isnull().sum()\n",
    "print(\"Number of missing values in each column:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_five_day_windows(df):\n",
    "    # Ensure that 'time' column is in datetime format\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    \n",
    "    # Sort data to ensure time sequence within each vessel\n",
    "    df = df.sort_values(by=['vesselId', 'time']).reset_index(drop=True)\n",
    "    \n",
    "    window_size_days = 5\n",
    "    windows = []\n",
    "\n",
    "    for vessel_id, group in df.groupby('vesselId'):\n",
    "        group = group.sort_values(by='time')\n",
    "        unique_dates = group['time'].dt.date.unique()\n",
    "\n",
    "        for start_idx in range(len(unique_dates) - window_size_days + 1):\n",
    "            start_date = unique_dates[start_idx]\n",
    "            end_date = unique_dates[start_idx + window_size_days - 1]\n",
    "            window = group[(group['time'].dt.date >= start_date) & (group['time'].dt.date <= end_date)]\n",
    "\n",
    "            # Skip empty windows\n",
    "            if len(window) == 0:\n",
    "                continue\n",
    "\n",
    "            # Reference row: the first row in the window\n",
    "            reference_row = window.iloc[0]\n",
    "\n",
    "            # Append each row in this window with reference features from the first row\n",
    "            for _, row in window.iterrows():\n",
    "                windows.append({\n",
    "                    'vesselId': row['vesselId'],\n",
    "                    'time': row['time'],\n",
    "                    'latitude': row['latitude'],\n",
    "                    'longitude': row['longitude'],\n",
    "                    'cog_sin': row['cog_sin'],\n",
    "                    'cog_cos': row['cog_cos'],\n",
    "                    'cog' : row['cog'],\n",
    "                    'sog': row['sog'],\n",
    "                    'rot': row['rot'],\n",
    "                    'under_way': row['under_way'],\n",
    "                    'length' : row['length'],\n",
    "                    'breadth': row['breadth'],\n",
    "                    # 'DWT': row['DWT'],\n",
    "                    'GT': row['GT'],\n",
    "                    # 'vessel_deep_sea': row['vessel_deep_sea'],\n",
    "                    # Features based on the first row in the window\n",
    "                    'latitude_first': reference_row['latitude'],\n",
    "                    'longitude_first': reference_row['longitude'],\n",
    "                    'cog_sin_first': reference_row['cog_sin'],\n",
    "                    'cog_cos_first': reference_row['cog_cos'],\n",
    "                    'sog_first': reference_row['sog'],\n",
    "                    'rot_first': reference_row['rot'],\n",
    "                    'under_way_first': reference_row['under_way'],\n",
    "                    'time_since_start': (row['time'] - reference_row['time']).total_seconds()\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a)) \n",
    "    r = 6371  # Radius of Earth in kilometers\n",
    "    return r * c  # Distance in kilometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "def calculate_convex_hull_area(lats, lons):\n",
    "    \"\"\"Calculate the area of the convex hull formed by the given latitudes and longitudes.\"\"\"\n",
    "    # Create a 2D array of coordinates\n",
    "    points = np.array(list(zip(lons, lats)))  # Note: Longitude first for ConvexHull\n",
    "    if len(points) < 3:  # Convex hull requires at least 3 points\n",
    "        return 0.0  # No area if fewer than 3 points\n",
    "    \n",
    "    # Calculate the convex hull\n",
    "    hull = ConvexHull(points)\n",
    "    \n",
    "    # Calculate area based on the convex hull\n",
    "    return hull.volume  # Volume is the area for 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def future_position(lat, lon, cog, sog, time_diff):\n",
    "    \"\"\"\n",
    "    Calculate the future position given the current latitude, longitude, COG, SOG, and time difference in seconds.\n",
    "    \"\"\"\n",
    "    # Convert COG from degrees to radians\n",
    "    cog_rad = np.radians(cog)\n",
    "\n",
    "    # Calculate distance traveled in meters\n",
    "    distance = sog * time_diff  # distance = speed * time\n",
    "\n",
    "    # Calculate future latitude and longitude\n",
    "    future_lat = lat + (distance * np.cos(cog_rad)) / 111320  # 111320 meters per degree latitude\n",
    "    future_lon = lon + (distance * np.sin(cog_rad)) / (111320 * np.cos(np.radians(lat)))  # adjust for longitude\n",
    "\n",
    "    return future_lat, future_lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(train):\n",
    "    train = train.copy()\n",
    "    train = train.sort_values(by=['vesselId', 'time']).reset_index(drop=True)\n",
    "\n",
    "    # # Handle NaNs\n",
    "    # train[['latitude', 'longitude', 'cog', 'time']] = (\n",
    "    #     train.groupby('vesselId')[['latitude', 'longitude', 'cog', 'time']].apply(lambda x: x.ffill().bfill())\n",
    "    # ).reset_index(drop=True)\n",
    "\n",
    "    features = pd.DataFrame()\n",
    "    features['vesselId'] = train['vesselId']\n",
    "    features['time'] = train['time'] \n",
    "    features['latitude'] = train['latitude']\n",
    "    features['longitude'] = train['longitude']\n",
    "    features['cog'] = train['cog']\n",
    "    features['sog'] = train['sog']\n",
    "    features['rot'] = train['rot']\n",
    "    features['under_way'] = train['navstat'].isin([0, 8]).astype(int)\n",
    "    features['cog_rad'] = np.radians(features['cog'])\n",
    "    features['cog_sin'] = np.sin(features['cog_rad'])\n",
    "    features['cog_cos'] = np.cos(features['cog_rad'])\n",
    "    features['length'] = train['length']\n",
    "    features['breadth'] = train['breadth']\n",
    "    features['GT'] = train['GT']\n",
    "    \n",
    "    features = create_five_day_windows(features)\n",
    "\n",
    "    features['latitude_port'] = train['latitude_port']\n",
    "    features['longitude_port'] = train['longitude_port']\n",
    "\n",
    "    features['distance_to_port'] = haversine(features['latitude'], features['longitude'], \n",
    "                                              features['latitude_port'], features['longitude_port'])\n",
    "    \n",
    "    features['time_diff'] = features.groupby('vesselId')['time'].diff().dt.total_seconds().fillna(0)\n",
    "\n",
    "    # Calculate future positions\n",
    "    future_positions = features.apply(lambda row: future_position(\n",
    "        row['latitude'], row['longitude'], row['cog'], row['sog'], row['time_diff']), axis=1)\n",
    "\n",
    "    features['future_latitude'], features['future_longitude'] = zip(*future_positions)\n",
    "    \n",
    "    features['area_covered'] = features.apply(lambda row: calculate_convex_hull_area(\n",
    "        features[(features['vesselId'] == row['vesselId']) & (features['time'] <= row['time'])]['latitude'].tolist(),\n",
    "        features[(features['vesselId'] == row['vesselId']) & (features['time'] <= row['time'])]['longitude'].tolist()), axis=1)\n",
    "\n",
    "    # Calculate cumulative area covered for each vessel\n",
    "    features['cumulative_area_covered'] = features.groupby('vesselId')['area_covered'].cumsum()\n",
    " \n",
    "    # Additional time-based features\n",
    "    features['month'] = features['time'].dt.month\n",
    "    features['day'] = features['time'].dt.day\n",
    "    features['hour'] = features['time'].dt.hour\n",
    "    features['minute'] = features['time'].dt.minute\n",
    "    # features['day_of_week'] = features['time'].dt.dayofweek\n",
    "\n",
    "    return features\n",
    "\n",
    "train_features = feature_engineering(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_values = train_features.isnull().sum()\n",
    "print(nan_values)\n",
    "\n",
    "\n",
    "# Drop the columns 'time' and 'rot'\n",
    "train_features = train_features.drop(columns=['time', 'rot_first'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_last_features(features):\n",
    "    # Assuming that the last row for every vesselId is the most recent\n",
    "    last_features = features.groupby('vesselId').last().reset_index()\n",
    "    return last_features\n",
    "\n",
    "last_features = find_last_features(train_features)\n",
    "# last_features.drop(columns=['DWT']) \n",
    "last_features.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define features and target\n",
    "y = train_features[['latitude', 'longitude']]  \n",
    "X = train_features.drop(columns=['latitude', 'longitude', 'vesselId']) \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(max_depth=25, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300],            # Number of trees in the forest\n",
    "    'max_depth': [5, 10, 25, None],             # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5],           # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2],            # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt'],      # The number of features to consider when looking for the best split\n",
    "    'bootstrap': [True, False]             # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Perform Randomized Search\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                                   n_iter=20, scoring='neg_mean_squared_error', cv=5, verbose=1, random_state=42)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Output the best parameters and score\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best score (negative mean squared error): {-random_search.best_score_}\")\n",
    "\n",
    "# best_model = xgb.XGBRegressor()\n",
    "\n",
    "# Fit the model\n",
    "best_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Get feature importances\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Step 2: Print feature importances\n",
    "print(\"Feature Importances:\")\n",
    "print(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare test data for predictions\n",
    "def prepare_test_for_predictions(test, last_features):\n",
    "    test = test.copy()\n",
    "    prepared_test = pd.DataFrame()\n",
    "\n",
    "    # Create a time column in last features\n",
    "    last_features['year'] = 2024\n",
    "    last_features['time'] = pd.to_datetime(\n",
    "        last_features[['year', 'month', 'day', 'hour', 'minute']]\n",
    "    )\n",
    "\n",
    "    # Add the columns vesselId and time\n",
    "    prepared_test['vesselId'] = test['vesselId']\n",
    "    prepared_test['time'] = test['time']\n",
    "\n",
    "    # For each vessel, add the last seen features to the prepared test\n",
    "    prepared_test = prepared_test.merge(last_features, on='vesselId', how='left', suffixes=('', '_last'))\n",
    "\n",
    "    print(prepared_test.head())\n",
    "\n",
    "    # Move the last_features to the reference row in the windows\n",
    "    prepared_test['latitude_first'] = prepared_test['latitude']\n",
    "    prepared_test['longitude_first'] = prepared_test['longitude']\n",
    "    prepared_test['cog_sin_first'] = prepared_test['cog_sin']\n",
    "    prepared_test['cog_cos_first'] = prepared_test['cog_cos']  # Fixed typo here\n",
    "    prepared_test['sog_first'] = prepared_test['sog']\n",
    "    prepared_test['under_way_first'] = prepared_test['under_way']\n",
    "    prepared_test['time_since_start'] = (prepared_test['time'] - prepared_test['time_last']).dt.total_seconds()\n",
    "\n",
    "    # Split the time column into month, day, hour, minute\n",
    "    prepared_test['month'] = test['time'].dt.month\n",
    "    prepared_test['day'] = test['time'].dt.day\n",
    "    prepared_test['hour'] = test['time'].dt.hour\n",
    "    prepared_test['minute'] = test['time'].dt.minute\n",
    "\n",
    "    # prepared_test['length'] = prepared_test['length']  # Ensure this column exists in 'prepared_test'\n",
    "    # prepared_test['breadth'] = prepared_test['breadth']  # Ensure this column exists in 'prepared_test'\n",
    "    # # prepared_test['DWT'] = prepared_test['DWT']  # Ensure this column exists in 'prepared_test'\n",
    "    # prepared_test['GT'] = prepared_test['GT']  # Ensure this column exists in 'prepared_test'\n",
    "    # prepared_test['vessel_deep_sea'] = prepared_test['vessel_deep_sea']  # Ensure this column exists in 'prepared_test'\n",
    "    # prepared_test['rot'] = prepared_test['rot']  # Ensure this column exists in 'prepared_test'\n",
    "    # # prepared_test['day_of_week'] = prepared_test['time'].dt.dayofweek  # Added missing day_of_week calculation\n",
    "\n",
    "    # Drop the columns that are no longer needed\n",
    "    prepared_test.drop(['time', 'time_last', 'year'], axis=1, inplace=True)\n",
    "\n",
    "    # Reorder the columns\n",
    "    prepared_test = prepared_test[['cog_sin', 'cog_cos', 'sog', 'rot', 'under_way', 'length', 'breadth',\n",
    "       'GT', 'latitude_first', 'longitude_first', 'cog_sin_first',\n",
    "       'cog_cos_first', 'sog_first', 'under_way_first', 'time_since_start',\n",
    "       'latitude_port', 'longitude_port', 'distance_to_port', 'month', 'day',\n",
    "       'hour', 'minute'\n",
    "                                ]]\n",
    "    \n",
    "\n",
    "    return prepared_test\n",
    "\n",
    "# Prepare the test DataFrame\n",
    "test_df = prepare_test_for_predictions(test, last_features)\n",
    "print(test_df.head())\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(test_df)\n",
    "print(predictions)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions, columns=['latitude_predicted', 'longitude_predicted'])\n",
    "predictions_df['ID'] = range(len(predictions_df))\n",
    "predictions_df = predictions_df[['ID', 'longitude_predicted', 'latitude_predicted']]\n",
    "\n",
    "# Save to CSV\n",
    "predictions_df.to_csv('predictions_ing_wfix.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'test' and 'predictions_df' are already defined and contain the necessary data\n",
    "merged_df = pd.merge(test, predictions_df, on='ID', how='left')\n",
    "\n",
    "# Print the columns to verify\n",
    "print(\"Columns in merged_df before dropping:\", merged_df.columns.tolist())\n",
    "\n",
    "# Drop the specified columns, checking if they exist first\n",
    "columns_to_drop = ['ID', 'scaling_factor']\n",
    "for col in columns_to_drop:\n",
    "    if col in merged_df.columns:\n",
    "        merged_df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# Alternatively, you can drop them directly with error handling\n",
    "# merged_df.drop(columns=[col for col in columns_to_drop if col in merged_df.columns], inplace=True)\n",
    "\n",
    "# Print the columns after the drop\n",
    "print(\"Columns in merged_df after dropping:\", merged_df.columns.tolist())\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('data/submissions/predictions_5_5d_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df.to_csv('data/submissions/plotting_boats.csv')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m125"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
